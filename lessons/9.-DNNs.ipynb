{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvtLYZzqu2lEDegEe3oUtx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ahmSP6iLPy2",
        "colab_type": "text"
      },
      "source": [
        "# Exercises: CIFAR10 training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJyciNhAPw9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Ojo3RGSKxe",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEaq4cLYP_3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "            units=100,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal'\n",
        "        )\n",
        "    )\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdttQGtPSMEh",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd8QEOglRZld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8da7dd61-960d-4af8-bc38-44f43e42747a"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "X_train_full.shape, y_train_full.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZvlTdlGyEx",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIehvWHeSKEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZMkwtanSPnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c074452-77f7-4984-c7b8-d34aa0cf3a38"
      },
      "source": [
        "def get_logs_dir():\n",
        "    now = time.strftime('%d_%m_%Y-%H_%M_%H')\n",
        "    return os.path.join('./logs', now)\n",
        "\n",
        "gpu_name = tf.test.gpu_device_name()\n",
        "logs_dir = get_logs_dir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(logs_dir)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "\n",
        "with tf.device(gpu_name):\n",
        "    optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer = optimizer,\n",
        "        metrics='accuracy'\n",
        "    )\n",
        "\n",
        "    history_1 = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[\n",
        "            tensorboard_cb,\n",
        "            early_stopping_cb\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "   2/1407 [..............................] - ETA: 3:16 - loss: 3.5960 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.2611s). Check your callbacks.\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.9227 - accuracy: 0.3027 - val_loss: 1.7982 - val_accuracy: 0.3474\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7135 - accuracy: 0.3829 - val_loss: 1.7148 - val_accuracy: 0.3658\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.6279 - accuracy: 0.4134 - val_loss: 1.6666 - val_accuracy: 0.3836\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5706 - accuracy: 0.4336 - val_loss: 1.6455 - val_accuracy: 0.4172\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5266 - accuracy: 0.4516 - val_loss: 1.5641 - val_accuracy: 0.4318\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4919 - accuracy: 0.4661 - val_loss: 1.5337 - val_accuracy: 0.4430\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4597 - accuracy: 0.4761 - val_loss: 1.5310 - val_accuracy: 0.4448\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4314 - accuracy: 0.4880 - val_loss: 1.4907 - val_accuracy: 0.4658\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4089 - accuracy: 0.4955 - val_loss: 1.4937 - val_accuracy: 0.4616\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3862 - accuracy: 0.5036 - val_loss: 1.5030 - val_accuracy: 0.4592\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3687 - accuracy: 0.5101 - val_loss: 1.4878 - val_accuracy: 0.4644\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3478 - accuracy: 0.5174 - val_loss: 1.4742 - val_accuracy: 0.4744\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3292 - accuracy: 0.5231 - val_loss: 1.4683 - val_accuracy: 0.4736\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3128 - accuracy: 0.5308 - val_loss: 1.4259 - val_accuracy: 0.4972\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2958 - accuracy: 0.5369 - val_loss: 1.4556 - val_accuracy: 0.4766\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2798 - accuracy: 0.5443 - val_loss: 1.4452 - val_accuracy: 0.4910\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2642 - accuracy: 0.5480 - val_loss: 1.4430 - val_accuracy: 0.4920\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2481 - accuracy: 0.5517 - val_loss: 1.4367 - val_accuracy: 0.4968\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2345 - accuracy: 0.5574 - val_loss: 1.4378 - val_accuracy: 0.4882\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2199 - accuracy: 0.5639 - val_loss: 1.4400 - val_accuracy: 0.4884\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2117 - accuracy: 0.5632 - val_loss: 1.4781 - val_accuracy: 0.4842\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1940 - accuracy: 0.5726 - val_loss: 1.4246 - val_accuracy: 0.4992\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1796 - accuracy: 0.5794 - val_loss: 1.4302 - val_accuracy: 0.4928\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1666 - accuracy: 0.5833 - val_loss: 1.4368 - val_accuracy: 0.4948\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1528 - accuracy: 0.5878 - val_loss: 1.4015 - val_accuracy: 0.5130\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1388 - accuracy: 0.5926 - val_loss: 1.4529 - val_accuracy: 0.4954\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1248 - accuracy: 0.5990 - val_loss: 1.4674 - val_accuracy: 0.4944\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1142 - accuracy: 0.6017 - val_loss: 1.4742 - val_accuracy: 0.4910\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1020 - accuracy: 0.6073 - val_loss: 1.4617 - val_accuracy: 0.4966\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0903 - accuracy: 0.6098 - val_loss: 1.4610 - val_accuracy: 0.5044\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0762 - accuracy: 0.6153 - val_loss: 1.4925 - val_accuracy: 0.4950\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0631 - accuracy: 0.6202 - val_loss: 1.4683 - val_accuracy: 0.4986\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0539 - accuracy: 0.6245 - val_loss: 1.5052 - val_accuracy: 0.5020\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0411 - accuracy: 0.6283 - val_loss: 1.4889 - val_accuracy: 0.5002\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0277 - accuracy: 0.6328 - val_loss: 1.4905 - val_accuracy: 0.5006\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0180 - accuracy: 0.6362 - val_loss: 1.4915 - val_accuracy: 0.4918\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0068 - accuracy: 0.6407 - val_loss: 1.4796 - val_accuracy: 0.5096\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9938 - accuracy: 0.6440 - val_loss: 1.5299 - val_accuracy: 0.4940\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9827 - accuracy: 0.6489 - val_loss: 1.5058 - val_accuracy: 0.5030\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9691 - accuracy: 0.6536 - val_loss: 1.5184 - val_accuracy: 0.5006\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9606 - accuracy: 0.6567 - val_loss: 1.5296 - val_accuracy: 0.5058\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9505 - accuracy: 0.6612 - val_loss: 1.5173 - val_accuracy: 0.5072\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9409 - accuracy: 0.6642 - val_loss: 1.5659 - val_accuracy: 0.4918\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9266 - accuracy: 0.6690 - val_loss: 1.6902 - val_accuracy: 0.4706\n",
            "Epoch 45/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9155 - accuracy: 0.6735 - val_loss: 1.5503 - val_accuracy: 0.5078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unnJ08dI-ov4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "778e75a1-dc9f-4e3a-9662-96ca036a3b5b"
      },
      "source": [
        "model.save('model_1.h5')\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step - loss: 1.5503 - accuracy: 0.5078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.55025053024292, 0.5077999830245972]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYspLJ3rG2xu",
        "colab_type": "text"
      },
      "source": [
        "## Train with batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RIXcAaCmETz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d240c7a3-a324-464d-b534-fa5b704b1213"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "logs_dir = get_logs_dir()\n",
        "\n",
        "# Model\n",
        "model_bn = keras.models.Sequential()\n",
        "\n",
        "model_bn.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "model_bn.add(keras.layers.BatchNormalization())\n",
        "for _ in range(20):\n",
        "    model_bn.add(\n",
        "        keras.layers.Dense(\n",
        "            units=100,\n",
        "            kernel_initializer='he_normal'\n",
        "        )\n",
        "    )\n",
        "    model_bn.add(\n",
        "        keras.layers.BatchNormalization()\n",
        "    )\n",
        "    model_bn.add(\n",
        "        keras.layers.Activation('elu')\n",
        "    )\n",
        "model_bn.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Training\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(logs_dir + '_bn_1')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"bn_model.h5\", save_best_only=True)\n",
        "\n",
        "with tf.device(gpu_name):\n",
        "    optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
        "    model_bn.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer = optimizer,\n",
        "        metrics='accuracy'\n",
        "    )\n",
        "\n",
        "    history_bn = model_bn.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[\n",
        "            early_stopping_cb,\n",
        "            model_checkpoint_cb,\n",
        "            tensorboard_cb,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "model_bn.save('bn_model.h5')\n",
        "print(model_bn.evaluate(X_valid, y_valid))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "   2/1407 [..............................] - ETA: 8:20 - loss: 2.8675 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0493s vs `on_train_batch_end` time: 0.6636s). Check your callbacks.\n",
            "1407/1407 [==============================] - 43s 30ms/step - loss: 1.8377 - accuracy: 0.3421 - val_loss: 1.6416 - val_accuracy: 0.4134\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.6630 - accuracy: 0.4099 - val_loss: 1.6124 - val_accuracy: 0.4182\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.5956 - accuracy: 0.4321 - val_loss: 1.5340 - val_accuracy: 0.4410\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.5487 - accuracy: 0.4464 - val_loss: 1.4964 - val_accuracy: 0.4640\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.5011 - accuracy: 0.4648 - val_loss: 1.4506 - val_accuracy: 0.4836\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.4661 - accuracy: 0.4769 - val_loss: 1.4245 - val_accuracy: 0.4918\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 43s 30ms/step - loss: 1.4349 - accuracy: 0.4892 - val_loss: 1.4098 - val_accuracy: 0.4930\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.4051 - accuracy: 0.4999 - val_loss: 1.3903 - val_accuracy: 0.5074\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.3820 - accuracy: 0.5089 - val_loss: 1.3635 - val_accuracy: 0.5172\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.3622 - accuracy: 0.5179 - val_loss: 1.3671 - val_accuracy: 0.5188\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.3418 - accuracy: 0.5236 - val_loss: 1.3374 - val_accuracy: 0.5248\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.3217 - accuracy: 0.5321 - val_loss: 1.3602 - val_accuracy: 0.5142\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.3013 - accuracy: 0.5375 - val_loss: 1.3656 - val_accuracy: 0.5220\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2825 - accuracy: 0.5437 - val_loss: 1.3566 - val_accuracy: 0.5268\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2635 - accuracy: 0.5538 - val_loss: 1.3785 - val_accuracy: 0.5162\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2557 - accuracy: 0.5557 - val_loss: 1.3615 - val_accuracy: 0.5216\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2377 - accuracy: 0.5600 - val_loss: 1.3337 - val_accuracy: 0.5242\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2210 - accuracy: 0.5687 - val_loss: 1.3245 - val_accuracy: 0.5348\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.2075 - accuracy: 0.5752 - val_loss: 1.3511 - val_accuracy: 0.5302\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1947 - accuracy: 0.5799 - val_loss: 1.3559 - val_accuracy: 0.5248\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1796 - accuracy: 0.5836 - val_loss: 1.3479 - val_accuracy: 0.5290\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.1649 - accuracy: 0.5876 - val_loss: 1.3492 - val_accuracy: 0.5262\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1541 - accuracy: 0.5932 - val_loss: 1.3425 - val_accuracy: 0.5354\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1365 - accuracy: 0.6001 - val_loss: 1.3052 - val_accuracy: 0.5420\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1284 - accuracy: 0.6019 - val_loss: 1.3204 - val_accuracy: 0.5492\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1166 - accuracy: 0.6053 - val_loss: 1.3391 - val_accuracy: 0.5336\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1040 - accuracy: 0.6096 - val_loss: 1.3262 - val_accuracy: 0.5452\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1010 - accuracy: 0.6123 - val_loss: 1.3497 - val_accuracy: 0.5376\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0896 - accuracy: 0.6163 - val_loss: 1.3295 - val_accuracy: 0.5426\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0771 - accuracy: 0.6207 - val_loss: 1.3243 - val_accuracy: 0.5420\n",
            "Epoch 31/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0637 - accuracy: 0.6246 - val_loss: 1.3419 - val_accuracy: 0.5396\n",
            "Epoch 32/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0577 - accuracy: 0.6252 - val_loss: 1.3498 - val_accuracy: 0.5404\n",
            "Epoch 33/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0437 - accuracy: 0.6317 - val_loss: 1.3482 - val_accuracy: 0.5446\n",
            "Epoch 34/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0381 - accuracy: 0.6314 - val_loss: 1.3459 - val_accuracy: 0.5492\n",
            "Epoch 35/1000\n",
            "1407/1407 [==============================] - 40s 29ms/step - loss: 1.0274 - accuracy: 0.6398 - val_loss: 1.3313 - val_accuracy: 0.5468\n",
            "Epoch 36/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0227 - accuracy: 0.6390 - val_loss: 1.3579 - val_accuracy: 0.5410\n",
            "Epoch 37/1000\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.0069 - accuracy: 0.6447 - val_loss: 1.3495 - val_accuracy: 0.5420\n",
            "Epoch 38/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.0024 - accuracy: 0.6460 - val_loss: 1.3401 - val_accuracy: 0.5468\n",
            "Epoch 39/1000\n",
            "1407/1407 [==============================] - 43s 30ms/step - loss: 0.9869 - accuracy: 0.6492 - val_loss: 1.3650 - val_accuracy: 0.5466\n",
            "Epoch 40/1000\n",
            "1407/1407 [==============================] - 43s 30ms/step - loss: 0.9830 - accuracy: 0.6555 - val_loss: 1.3707 - val_accuracy: 0.5420\n",
            "Epoch 41/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9725 - accuracy: 0.6564 - val_loss: 1.3671 - val_accuracy: 0.5444\n",
            "Epoch 42/1000\n",
            "1407/1407 [==============================] - 40s 29ms/step - loss: 0.9663 - accuracy: 0.6573 - val_loss: 1.3511 - val_accuracy: 0.5464\n",
            "Epoch 43/1000\n",
            "1407/1407 [==============================] - 40s 29ms/step - loss: 0.9624 - accuracy: 0.6601 - val_loss: 1.3664 - val_accuracy: 0.5512\n",
            "Epoch 44/1000\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 0.9472 - accuracy: 0.6666 - val_loss: 1.3840 - val_accuracy: 0.5366\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.3840 - accuracy: 0.5366\n",
            "[1.3839503526687622, 0.5365999937057495]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V1-til7G713",
        "colab_type": "text"
      },
      "source": [
        "## Train self-normalized network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mksxc4_0Amrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcb50c07-1999-41df-e2f3-6df8ca980e05"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "logs_dir = get_logs_dir()\n",
        "\n",
        "# Model\n",
        "model_snn = keras.models.Sequential()\n",
        "\n",
        "model_snn.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model_snn.add(\n",
        "        keras.layers.Dense(\n",
        "            units=100,\n",
        "            kernel_initializer='lecun_normal',\n",
        "            activation='selu'\n",
        "        )\n",
        "    )\n",
        "model_snn.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Training\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(logs_dir + '_snn_2')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"snn_model.h5\", save_best_only=True)\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "with tf.device(gpu_name):\n",
        "    optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
        "    model_snn.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer = optimizer,\n",
        "        metrics='accuracy'\n",
        "    )\n",
        "\n",
        "    history_snn = model_snn.fit(\n",
        "        X_train_scaled,\n",
        "        y_train,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[\n",
        "            early_stopping_cb,\n",
        "            model_checkpoint_cb,\n",
        "            tensorboard_cb,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "model_snn.save('snn_model.h5')\n",
        "print(model_snn.evaluate(X_valid_scaled, y_valid))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "   2/1407 [..............................] - ETA: 3:27 - loss: 3.0440 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0197s vs `on_train_batch_end` time: 0.2738s). Check your callbacks.\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.9258 - accuracy: 0.3081 - val_loss: 1.8344 - val_accuracy: 0.3380\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7161 - accuracy: 0.3908 - val_loss: 1.6946 - val_accuracy: 0.3990\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6147 - accuracy: 0.4301 - val_loss: 1.6928 - val_accuracy: 0.4004\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5447 - accuracy: 0.4544 - val_loss: 1.6569 - val_accuracy: 0.4220\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4904 - accuracy: 0.4764 - val_loss: 1.6517 - val_accuracy: 0.4404\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4449 - accuracy: 0.4948 - val_loss: 1.5270 - val_accuracy: 0.4732\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3956 - accuracy: 0.5090 - val_loss: 1.5402 - val_accuracy: 0.4632\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3585 - accuracy: 0.5247 - val_loss: 1.4940 - val_accuracy: 0.4766\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3244 - accuracy: 0.5388 - val_loss: 1.5171 - val_accuracy: 0.4610\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2910 - accuracy: 0.5514 - val_loss: 1.4612 - val_accuracy: 0.4944\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2579 - accuracy: 0.5632 - val_loss: 1.5151 - val_accuracy: 0.4874\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2327 - accuracy: 0.5740 - val_loss: 1.5073 - val_accuracy: 0.4874\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1989 - accuracy: 0.5832 - val_loss: 1.5002 - val_accuracy: 0.4938\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1836 - accuracy: 0.5910 - val_loss: 1.4716 - val_accuracy: 0.4998\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1549 - accuracy: 0.6029 - val_loss: 1.5020 - val_accuracy: 0.5062\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1323 - accuracy: 0.6082 - val_loss: 1.5343 - val_accuracy: 0.4980\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1056 - accuracy: 0.6196 - val_loss: 1.5023 - val_accuracy: 0.5010\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0904 - accuracy: 0.6256 - val_loss: 1.5164 - val_accuracy: 0.5108\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0658 - accuracy: 0.6371 - val_loss: 1.5361 - val_accuracy: 0.5164\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0380 - accuracy: 0.6460 - val_loss: 1.5696 - val_accuracy: 0.5048\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0206 - accuracy: 0.6516 - val_loss: 1.5763 - val_accuracy: 0.5130\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0029 - accuracy: 0.6589 - val_loss: 1.5691 - val_accuracy: 0.5052\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9894 - accuracy: 0.6659 - val_loss: 1.6104 - val_accuracy: 0.4982\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9712 - accuracy: 0.6718 - val_loss: 1.5995 - val_accuracy: 0.5124\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9515 - accuracy: 0.6803 - val_loss: 1.5276 - val_accuracy: 0.5180\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9393 - accuracy: 0.6828 - val_loss: 1.6114 - val_accuracy: 0.5034\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9181 - accuracy: 0.6895 - val_loss: 1.5892 - val_accuracy: 0.5208\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 2615.0237 - accuracy: 0.6810 - val_loss: 2.3920 - val_accuracy: 0.4370\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3562 - accuracy: 0.5726 - val_loss: 1.6112 - val_accuracy: 0.4792\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1069 - accuracy: 0.6215 - val_loss: 1.5663 - val_accuracy: 0.4920\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.5663 - accuracy: 0.4920\n",
            "[1.566311240196228, 0.492000013589859]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCMJGdcNIwTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d5dc585-0b4d-4f9f-8a4f-824130b57a12"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "logs_dir = get_logs_dir()\n",
        "\n",
        "# Model\n",
        "model_snn_da = keras.models.Sequential()\n",
        "\n",
        "model_snn_da.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model_snn_da.add(\n",
        "        keras.layers.Dense(\n",
        "            units=100,\n",
        "            kernel_initializer='lecun_normal',\n",
        "            activation='selu'\n",
        "        )\n",
        "    )\n",
        "model_snn_da.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model_snn_da.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Training\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(logs_dir + '_snn_da_1')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"snn_da_model.h5\", save_best_only=True)\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "with tf.device(gpu_name):\n",
        "    optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
        "    model_snn_da.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer = optimizer,\n",
        "        metrics='accuracy'\n",
        "    )\n",
        "\n",
        "    history_snn_da = model_snn_da.fit(\n",
        "        X_train_scaled,\n",
        "        y_train,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[\n",
        "            early_stopping_cb,\n",
        "            model_checkpoint_cb,\n",
        "            tensorboard_cb,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "model_snn_da.save('snn_da_model.h5')\n",
        "print(model_snn_da.evaluate(X_valid_scaled, y_valid))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "   2/1407 [..............................] - ETA: 3:51 - loss: 2.9857 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.3080s). Check your callbacks.\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.8946 - accuracy: 0.3225 - val_loss: 1.7059 - val_accuracy: 0.3850\n",
            "Epoch 2/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6681 - accuracy: 0.4082 - val_loss: 1.6394 - val_accuracy: 0.4072\n",
            "Epoch 3/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5780 - accuracy: 0.4428 - val_loss: 1.6245 - val_accuracy: 0.4318\n",
            "Epoch 4/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5025 - accuracy: 0.4716 - val_loss: 1.5461 - val_accuracy: 0.4546\n",
            "Epoch 5/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4472 - accuracy: 0.4909 - val_loss: 1.5535 - val_accuracy: 0.4650\n",
            "Epoch 6/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4039 - accuracy: 0.5098 - val_loss: 1.5309 - val_accuracy: 0.4830\n",
            "Epoch 7/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3627 - accuracy: 0.5269 - val_loss: 1.5735 - val_accuracy: 0.4782\n",
            "Epoch 8/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3176 - accuracy: 0.5426 - val_loss: 1.5168 - val_accuracy: 0.4882\n",
            "Epoch 9/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2880 - accuracy: 0.5541 - val_loss: 1.5233 - val_accuracy: 0.4950\n",
            "Epoch 10/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2516 - accuracy: 0.5666 - val_loss: 1.4991 - val_accuracy: 0.4914\n",
            "Epoch 11/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2220 - accuracy: 0.5791 - val_loss: 1.5650 - val_accuracy: 0.4994\n",
            "Epoch 12/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1947 - accuracy: 0.5868 - val_loss: 1.5270 - val_accuracy: 0.4976\n",
            "Epoch 13/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1615 - accuracy: 0.6029 - val_loss: 1.5486 - val_accuracy: 0.5038\n",
            "Epoch 14/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1454 - accuracy: 0.6070 - val_loss: 1.5481 - val_accuracy: 0.5090\n",
            "Epoch 15/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1114 - accuracy: 0.6173 - val_loss: 1.5999 - val_accuracy: 0.5060\n",
            "Epoch 16/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0895 - accuracy: 0.6247 - val_loss: 1.6201 - val_accuracy: 0.5062\n",
            "Epoch 17/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0741 - accuracy: 0.6335 - val_loss: 1.6180 - val_accuracy: 0.5120\n",
            "Epoch 18/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0426 - accuracy: 0.6442 - val_loss: 1.6128 - val_accuracy: 0.5100\n",
            "Epoch 19/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0190 - accuracy: 0.6536 - val_loss: 1.7410 - val_accuracy: 0.5044\n",
            "Epoch 20/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9978 - accuracy: 0.6616 - val_loss: 1.7288 - val_accuracy: 0.5146\n",
            "Epoch 21/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9834 - accuracy: 0.6663 - val_loss: 1.6916 - val_accuracy: 0.5082\n",
            "Epoch 22/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9648 - accuracy: 0.6697 - val_loss: 1.6921 - val_accuracy: 0.5164\n",
            "Epoch 23/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9457 - accuracy: 0.6821 - val_loss: 1.6933 - val_accuracy: 0.5016\n",
            "Epoch 24/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9243 - accuracy: 0.6875 - val_loss: 1.7702 - val_accuracy: 0.5080\n",
            "Epoch 25/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9112 - accuracy: 0.6904 - val_loss: 1.7741 - val_accuracy: 0.4990\n",
            "Epoch 26/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8940 - accuracy: 0.6976 - val_loss: 1.7744 - val_accuracy: 0.5034\n",
            "Epoch 27/1000\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9239 - accuracy: 0.6872 - val_loss: 1.7221 - val_accuracy: 0.5102\n",
            "Epoch 28/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8682 - accuracy: 0.7060 - val_loss: 1.7571 - val_accuracy: 0.5000\n",
            "Epoch 29/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8480 - accuracy: 0.7129 - val_loss: 1.8912 - val_accuracy: 0.5012\n",
            "Epoch 30/1000\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8322 - accuracy: 0.7185 - val_loss: 1.8540 - val_accuracy: 0.5004\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.8540 - accuracy: 0.5004\n",
            "[1.8539845943450928, 0.5004000067710876]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfbay9ZbOHnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "model_snn_mcda = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate)\n",
        "    if isinstance(layer, keras.layers.AlphaDropout)\n",
        "    else layer\n",
        "    for layer in model_snn_da.layers\n",
        "])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN1dcoEdRkTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
        "    predictions = [mc_model.predict(X) for _ in range(n_samples)]\n",
        "    return np.mean(predictions, axis=0)\n",
        "\n",
        "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
        "    probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
        "    return np.argmax(probas, axis=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyt3YhwISTm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1a3b9e97-d33f-451e-bf60-5a77692d07f6"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "y_pred = mc_dropout_predict_classes(model_snn_mcda, X_valid_scaled)\n",
        "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
        "accuracy"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKgkOTSCSb_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}